"""å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚

ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ï¼ˆwrite-then-rename + .bak + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ãªã©ã€
è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§å…±æœ‰ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’æä¾›ã™ã‚‹ã€‚
"""

from __future__ import annotations

import logging
import os
import shutil
import tempfile
from pathlib import Path
from typing import Callable

from app.i18n import t

logger = logging.getLogger(__name__)


def atomic_write(file_path: Path, content: str, *, create_backup: bool = True) -> None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒˆãƒŸãƒƒã‚¯ã«æ›¸ãè¾¼ã‚€ï¼ˆwrite-then-rename æ–¹å¼ï¼‰ã€‚

    1. <ãƒ•ã‚¡ã‚¤ãƒ«å>.tmp ã«æ–°ã—ã„å†…å®¹ã‚’æ›¸ãè¾¼ã‚€
    2. fsync ã§ãƒ‡ã‚£ã‚¹ã‚¯ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
    3. æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã° .bak ã¨ã—ã¦ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    4. .tmp â†’ æœ¬ä½“ã«ãƒªãƒãƒ¼ãƒ ï¼ˆOS ãƒ¬ãƒ™ãƒ«ã§ã‚¢ãƒˆãƒŸãƒƒã‚¯ï¼‰

    Args:
        file_path: æ›¸ãè¾¼ã¿å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        content: æ›¸ãè¾¼ã‚€å†…å®¹ï¼ˆæ–‡å­—åˆ—ï¼‰ã€‚
        create_backup: True ã®å ´åˆã€æ›¸ãè¾¼ã¿å‰ã«æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã® .bak ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    file_path = Path(file_path)
    file_path.parent.mkdir(parents=True, exist_ok=True)

    tmp_path = file_path.with_suffix(file_path.suffix + ".tmp")
    bak_path = file_path.with_suffix(file_path.suffix + ".bak")

    try:
        # 1. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(tmp_path, "w", encoding="utf-8") as f:
            f.write(content)
            # 2. fsync ã§ãƒ‡ã‚£ã‚¹ã‚¯ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
            f.flush()
            os.fsync(f.fileno())

        # 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
        if create_backup and file_path.exists():
            try:
                shutil.copy2(str(file_path), str(bak_path))
                logger.debug("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: %s", bak_path)
            except OSError as e:
                logger.warning("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—: %s â€” %s", bak_path, e)

        # 4. ãƒªãƒãƒ¼ãƒ ï¼ˆWindows ã§ã¯ os.replace ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ç›¸å½“ï¼‰
        os.replace(str(tmp_path), str(file_path))
        logger.debug("ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿å®Œäº†: %s", file_path)

    except Exception:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ®‹ã£ã¦ã„ã‚Œã°å‰Šé™¤
        if tmp_path.exists():
            try:
                tmp_path.unlink()
            except OSError:
                pass
        raise


def safe_read_with_fallback(
    file_path: Path,
    parser: Callable[[str], object],
    default_factory: Callable[[], object],
    *,
    notify_callback: Callable[[str, str], None] | None = None,
) -> object:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å¤±æ•—æ™‚ã¯ .bak â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã€‚

    Args:
        file_path: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        parser: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å—ã‘å–ã‚Šãƒ‘ãƒ¼ã‚¹çµæœã‚’è¿”ã™é–¢æ•°ã€‚
        default_factory: ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ã€‚
        notify_callback: è­¦å‘Šé€šçŸ¥ã‚’è¡Œã†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆtitle, messageï¼‰ã€‚None ãªã‚‰é€šçŸ¥ã‚¹ã‚­ãƒƒãƒ—ã€‚

    Returns:
        ãƒ‘ãƒ¼ã‚¹çµæœã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã€‚
    """
    file_path = Path(file_path)
    bak_path = file_path.with_suffix(file_path.suffix + ".bak")

    # 1. æœ¬ä½“èª­ã¿è¾¼ã¿
    if file_path.exists():
        try:
            raw = file_path.read_text(encoding="utf-8")
            result = parser(raw)
            logger.debug("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: %s", file_path)
            return result
        except Exception as e:
            logger.warning("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿/ãƒ‘ãƒ¼ã‚¹å¤±æ•—: %s â€” %s", file_path, e)

    # 2. .bak ã‹ã‚‰å¾©å…ƒ
    if bak_path.exists():
        try:
            raw = bak_path.read_text(encoding="utf-8")
            result = parser(raw)
            logger.warning(".bak ã‹ã‚‰å¾©å…ƒã—ã¾ã—ãŸ: %s", bak_path)
            if notify_callback:
                notify_callback(
                    t("utils.file_recovery"),
                    t("utils.restored_from_backup", name=file_path.name),
                )
            return result
        except Exception as e:
            logger.warning(".bak èª­ã¿è¾¼ã¿/ãƒ‘ãƒ¼ã‚¹å¤±æ•—: %s â€” %s", bak_path, e)

    # 3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    logger.warning("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: %s", file_path)
    if notify_callback:
        notify_callback(
            t("utils.file_recovery"),
            t("utils.regenerated_default", name=file_path.name),
        )
    return default_factory()


def estimate_tokens(text: str) -> int:
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹ï¼ˆç°¡æ˜“æ¨å®š: æ—¥è‹±æ··åœ¨ã‚’è€ƒæ…®ï¼‰ã€‚

    æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å¤šãå«ã‚€å ´åˆã‚’æƒ³å®šã—ã€1æ–‡å­—â‰’1.5ãƒˆãƒ¼ã‚¯ãƒ³ã§æ¦‚ç®—ã™ã‚‹ã€‚
    è‹±å˜èªãƒ™ãƒ¼ã‚¹ã®æ¨å®šï¼ˆç©ºç™½åŒºåˆ‡ã‚ŠÃ·0.75ï¼‰ã¨æ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ã®æ¨å®šã®åŠ é‡å¹³å‡ã‚’å–ã‚‹ã€‚

    Args:
        text: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã€‚

    Returns:
        æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆæ•´æ•°ï¼‰ã€‚
    """
    if not text:
        return 0
    # è‹±å˜èªãƒ™ãƒ¼ã‚¹ã®æ¨å®š
    word_count = len(text.split())
    word_based = int(word_count / 0.75)
    # æ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ã®æ¨å®šï¼ˆæ—¥æœ¬èªå‘ã‘ï¼‰
    char_based = int(len(text) * 0.5)
    # å¤§ãã„æ–¹ã‚’æ¡ç”¨ï¼ˆå®‰å…¨å´ã«å€’ã™ï¼‰
    return max(word_based, char_based)


def extract_topic_keys(md_content: str) -> list[dict[str, str]]:
    """ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚° MD ã‹ã‚‰ topic_key ã‚’æŠ½å‡ºã™ã‚‹ã€‚

    <!-- topic_key: ... --> å½¢å¼ã® HTML ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã™ã‚‹ã€‚
    ç›´å¾Œã® ### è¡Œã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«ã€**Q1ï¼ˆ4æŠï¼‰** / **Q2ï¼ˆè¨˜è¿°ï¼‰** ã®
    ç›´å¾Œã«ã‚ã‚‹å•é¡Œæ–‡ã‚‚ã‚ã‚ã›ã¦å–å¾—ã™ã‚‹ã€‚

    Args:
        md_content: ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚° MD ãƒ†ã‚­ã‚¹ãƒˆã€‚

    Returns:
        æŠ½å‡ºçµæœã®ãƒªã‚¹ãƒˆã€‚å„è¦ç´ ã¯
        {"topic_key": ..., "title": ..., "pattern": ...,
         "q1_text": ..., "q2_text": ...}ã€‚
    """
    import re

    results: list[dict[str, str]] = []
    topic_block_pattern = re.compile(
        r"<!--\s*topic_key:\s*(.+?)\s*-->\s*\n\s*###\s*(.+)",
        re.MULTILINE,
    )

    # å„ãƒˆãƒ”ãƒƒã‚¯ã®é–‹å§‹ä½ç½®ã‚’åé›†ã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²
    matches = list(topic_block_pattern.finditer(md_content))
    for i, match in enumerate(matches):
        topic_key = match.group(1).strip()
        title = match.group(2).strip()

        # ãƒ–ãƒ­ãƒƒã‚¯çµ‚ç«¯ï¼ˆæ¬¡ã®ãƒˆãƒ”ãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã®æ‰‹å‰ã€ã¾ãŸã¯æ–‡æœ«ï¼‰
        block_end = matches[i + 1].start() if i + 1 < len(matches) else len(md_content)
        block = md_content[match.start(): block_end]

        # Q1 å•é¡Œæ–‡: **Q1ï¼ˆ4æŠï¼‰** ã€œ æœ€åˆã®é¸æŠè‚¢ "- A)" ã®æ‰‹å‰ã¾ã§
        q1_text = ""
        q1_match = re.search(
            r"\*\*Q1ï¼ˆ4æŠï¼‰\*\*\s*\n+(.+?)(?=\n-\s*A[)ï¼‰]|\n---)",
            block,
            re.DOTALL,
        )
        if q1_match:
            q1_text = q1_match.group(1).strip()
            # å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒãƒ¼ã‚«ãƒ¼ ">" ã‚’é™¤å»ã—ã¦èª­ã¿ã‚„ã™ã
            q1_text = re.sub(r"^>\s?", "", q1_text, flags=re.MULTILINE).strip()

        # Q2 å•é¡Œæ–‡: **Q2ï¼ˆè¨˜è¿°ï¼‰** ã€œ æ¬¡ã® "---" ã®æ‰‹å‰ã¾ã§
        q2_text = ""
        q2_match = re.search(
            r"\*\*Q2ï¼ˆè¨˜è¿°ï¼‰\*\*\s*\n+(.+?)(?=\n---)",
            block,
            re.DOTALL,
        )
        if q2_match:
            q2_text = q2_match.group(1).strip()
            q2_text = re.sub(r"^>\s?", "", q2_text, flags=re.MULTILINE).strip()

        # ãƒãƒƒãƒä½ç½®ã‚ˆã‚Šå‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ¤å®š
        preceding = md_content[: match.start()]
        if "ğŸ“˜" in preceding and ("ğŸ“—" not in preceding or preceding.rfind("ğŸ“˜") > preceding.rfind("ğŸ“—")):
            topic_pattern = "learning"
        elif "ğŸ“—" in preceding:
            topic_pattern = "review"
        else:
            topic_pattern = "learning"

        results.append(
            {
                "topic_key": topic_key,
                "title": title,
                "pattern": topic_pattern,
                "q1_text": q1_text,
                "q2_text": q2_text,
            }
        )

    return results
